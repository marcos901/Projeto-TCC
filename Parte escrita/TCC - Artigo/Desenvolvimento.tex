\section{DESENVOLVIMENTO}
\subsection{MATERIAIS}
Os materiais usados no trabalho foram duas bases de dados ambas da NBA Advanced Stats\footnote{National Basketball Associativo} sendo uma da \textit{season} de 2014 a 2018 com 9.840 jogos com os dados armazenados em um arquivo csv, a outra indo da \textit{season} de 2007 a 2019 com 30.000 jogos com os dados armazenados em um banco de dados e sendo acessado através da nba-api PyPI. 

A ferramenta utilizada para o desenvolvimento foi o \textit{JupyterLab}, linguagem de programação {python} e o uso das bibliotecas  pandas, numpy, \textit{sklearn}, \textit{seaborn}, matplotlib.

A NBA advances stats e um site patrocinado pela SAP com o proposito e de manter um registros de toda liga da NBA e facilitar e acesso a essa informações pelas equipes e organizações. A nba-api PyPI e uma API para acesso a www.nba.com, o principal objetivo e mapear e analisar o maior numero posivel de jogos.

O \textit{jupyterlab} é um ambiente de desenvolvimento interativo baseado na \textit{web} para \textit{notebooks}. O \textit{jupyterlab} é facil de configurar e organizar, a interface do usuário para suporta uma ampla variedade de fluxos de trabalho em ciência de dados, computação científica e aprendizado de máquina.O \textit{jupyterlab} é extensível e modular e fácil de adicionar os \textit{plug-ins}, que adicionam novos componentes e se integram aos já existentes\cite{jupyter}.

Python é uma linguagem de programação criada por Guido van Rossum em 1991. Os objetivos do projeto da linguagem eram produtividade e legibilidade, é uma linguagem de alto nível, multi paradigma, suporta o paradigma orientado a objetos, imperativo, funcional e procedural. Possui tipagem dinâmica e uma de suas principais características é permitir a fácil leitura do código e exigir poucas linhas de código se comparado ao mesmo programa em outras linguagens\cite{python}.

O pandas é uma biblioteca de código aberto, licenciada por BSD \footnote{Berkeley Software Distribution}, que fornece estruturas de dados de alto desempenho e fáceis de usar e ferramentas de análise de dados para a linguagem de programação \textit{python}. O pandas ajuda a preencher essa lacuna, permitindo que você execute todo o fluxo de trabalho de análise de dados no \textit{python} sem precisar mudar para uma linguagem\cite{pandas}.

O numPy é uma biblioteca \textit{python} que é usada para realizar cálculos em \textit{arrays} multidimensionais. Fornecendo um grande conjunto de funções e operações que ajudam os programadores a executar facilmente cálculos numéricos.\cite{numpy}

O \textit{scikit learn} é uma biblioteca \textit{python} que é usada para aprendizado de máquina. Ela possui uma variedade de algoritmos incluindo vários algoritmos de classificação, regressão e agrupamento incluindo máquinas de vetores de suporte, florestas aleatórias, \textit{gradient boosting}, \textit{k-means}\cite{scikit}.

O matplotlib é uma biblioteca de plotagem 2D do python, é uma biblioteca que tenta facilitar e facilitar a gerar gráficos, histogramas, espectros de potência, gráficos de barras, gráficos de erros, gráficos de dispersão etc\cite{matplotlib}.

O seaborn é uma biblioteca de visualização de dados Python baseada no matplotlib . Ele fornece uma interface de alto nível para desenhar gráficos estatísticos atraentes e informativos.\cite{seaborn}


\subsection{METODOLOGIA}
Os algoritmos usados para as predições são os de regressão linear, regressão logística, k-NN\footnote{k-nearest neighbors},  arvore de decisão, floresta aleatória, máquinas de vetores de suporte.

O algoritmo de regressão linear responsável por modelar uma associação entre uma ou mais variáveis de saída e entrada. O processo de regressão pode ser dividido em duas categorias, as paramétricas, no qual o relacionamento entre as variáveis é conhecido, e não paramétricas onde não existe conhecimento preexistente entre as variáveis. As técnicas de regressão linear procuram a relação entre duas variáveis por meio de uma equação de uma linha reta\cite{Bogoni2019}.

A regressão logística é uma técnica utilizada para a estimação de uma variável de natureza binária, estimando o valor em 0 ou 1, sendo que as variáveis independentes podem ser de natureza categórica ou não. Igualmente como na regressão linear é
necessário aplicar pesos onde ajustam-se aos dados de treinamento do algoritmo, porém a regressão logística não procura a melhor reta que se ajuste aos dados, mas sim a melhor curva. A regressão logística calcula uma razão de probabilidade da variável alvo, que posteriormente é convertida em uma variável de base logarítmica, permitindo assim a classificação com base na aproximação de um dos valores\cite{Witten2011}.

O algoritmo k-NN é um método não paramétrico usado para classificação e regressão . Nos dois casos, a entrada consiste nos k exemplos de treinamento a saída depende se k-NN é usado para classificação ou regressão. Na classificação k-NN, a saída é uma associação de classe. Um objeto é classificado pelo voto de pluralidade de seus vizinhos, sendo o objeto atribuído à classe mais comum entre os k vizinhos mais próximos. Os vizinhos são obtidos de um conjunto de objetos para os quais a classe ou o valor da propriedade do objeto é conhecida\cite{KamgarParsi1985}.

O processo de classificação em uma árvore de decisão, acontece de maneira recursiva, de modo que o nó inicial representa o conjunta de dados, em seguida deve ser avaliado se os objetos são da mesma classe, sendo esse o caso o nó é considerado um nó folha, caso contrário um atributo precisa ser usado para dividir os dados. Este processo deve ser executado recursivamente, ele pode ser descontinuado caso faltarem atributos para realizar testes de divisão ou caso todos os registros forem da mesma classe\cite{castro}.

Florestas aleatórias são um grupo de árvores de decisões, nos quais juntos formam uma floresta. Estas árvores são geradas com base em um atributo aleatório que é o responsável pela divisão em cada nó da árvore. A precisão de uma floresta aleatória é determinada de acordo com a força de cada classificador da árvore, e também o nível de dependência entre eles, o melhor modo de atingir essa precisão é mantendo a força dos classificadores e não aumentar a correlação entre eles\cite{castro}.

A técnica de máquinas de vetores de suporte, têm como fundamento o aprendizado em cima da estatística, o algoritmo apresenta ótima performance na utilização de dados de alta dimensionalidade. O mesmo funciona através de um conceito de hiperplano, sendo definido um limite linear neste plano para realizar a classificação, o algoritmo possuí a função de detectar o hiperplano de margem máxima, aquele com a maior margem separação entre as classes, com o objetivo de apresentar menos erros de generalização em relação a margens menores\cite{Tan2009}.


